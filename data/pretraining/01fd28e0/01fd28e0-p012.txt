X-SPANFORMER
SPAN-AwARE ENCODER
Controller-aware injection into the encoder backbone: conditions the transformer via prefix insertion, attention shifts, Or gating pathways [30, 47, 37].
All stages are fully differentiable and trained jointly from supervision signals [7, 48].
4.1 Span Induction with Entropic Regularization
To identify compositional units latent in unstructured sequences, we treat all bounded-width sub- strings a8 candidate spans and learn a scoring function to assign each a salience probability: This differentiable selection mechanism is trained jointly with downstream objectives but regularized to maintain entropy-driven exploration early in training:  Inspired by principles from latent structure modeling [45, 15] and soft routing frameworks [43], our span induction stage maps an input sequence x € RLxd to a distribution P over all candidate spans S, followed by a sampling Or top-K filtering step that informs structural fusion. Let D = {(2() ,y())}I denote the training corpus, where each input 2() € RLxd consists of L contextual embeddings: We define the set of all contiguous spans of width at most Umax as:
S = {(i,j) |0 <i < j < min(i + Umax , L)}
Each span is encoded using & fixed pooling operator and scored by a function fo(wi:j) e R. The span distribution is then computed via softmax over all candidate scores:
exp( fe(.ij)) '(a,b)es exp( fo(wa:b)) `
To encourage diversity and avoid overconfident routing early in training, we introduce a temperature weighted Shannon entropy regularizer:
Lent = _Aent H(P);
H(P) = - Pij log Pij: (i,j)es
6)
The entropy coefficient decays exponentially:
= Ao exp( _yt) ,
where t is the training epoch; Ao the initial weight, and ~ 0 a decay rate: This annealing schedule mirrors techniques from curriculum learning [7 , 24].
Proposition 5 (Maximum Entropy of Uniform Span Distribution). Let S denote the set of valid spans defined in Equation (4), with   cardinality |S| = N . The entropy H(P) of any valid span distribution P, as8 defined im Equation (17) , is maximized when:
1 Pij = for all (i,j) € S: N
'8)
This yields:
Hmax  (P) = log/S1 = log N.
(9)
13
Pij
Aent !