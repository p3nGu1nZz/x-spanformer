X-SPANFORMER
SPAN-AwARE ENCODER
Proof: Follows directly from exponential decay bounds 0n entropy-regularized softmax distributions [75]. See Proposition 8 for detailed derivation
This result provides theoretical support for the routing sparsification observed in Section 5.4, con- firming that entropy scheduling is sufficient to yield selective, interpretable span patterns; provided Ao and ~ are chosen to balance exploration and convergence.
5.6 Future Benchmarks and Tasks
We outline evaluation pathways beyond the current architecture sketch; emphasizing both transfer- ability and interpretability:
Downstream: Apply X-Spanformer to named entity recognition (NER), abstractive summa- rization, latent syntax induction, and low-resource translation: Prior   work has  shown that span-based representations improve entity boundary detection [78], and that structured routing enhances summarization in data-scarce regimes [79, 80]. Latent syntax models have also ben- efited from unsupervised span induction [55], suggesting that X-Spanformer's controller-guided spans may offer a viable inductive bias:
Structural transfer: Warm-start span modules on synthetic corpora with known routing tem- plates, then freeze Or partially fine-tune only the task-specific decoder. This aligns with recent work on warm-starting and transfer learning for efficient adaptation [81, 80], and may reduce overfitting in low-resource domains: Controller probing: Freeze routing weights and inject either random Or interpretable controller vectors $ into downstream encoders: This enables causal probing of span semantics and disen- tanglement, similar to frozen transformer interventions in multimodal Or multilingual settings [82, 81].
These directions aim to validate the modularity and generalization capacity of X-Spanformer across both structured and unstructured tasks. We plan to release diagnostic notebooks and controller visualization tools to support reproducibility and community benchmarking:
Visualization Framework and Interpretability Interfaces
Interpretability is central to the X-Spanformer framework, not only for debugging but for validating the emergence of structured behavior from differentiable routing: We introduce a modular  visu- alization suite designed to capture dynamic routing patterns, evaluate alignment with linguistic structure; and probe causal effects of controller activations These interfaces build 0n the interpretability literature in structured attention [83, 84], entropy- based pruning [75, 53], and latent syntactic probing [85, 55]. Together, they scaffold an interactive environment for qualitative and quantitative analysis of controller behavior throughout training:
33