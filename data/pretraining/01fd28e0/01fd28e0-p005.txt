X-SPANFORMER
SPAN-AwARE ENCODER
This exhaustive enumeration is tractable for short sequences and compatible with global attention filtering, as used in segment-aware transformers [15, 17, 21]_ Each span candidate corresponds to a contiguous subsequence [hi, hj] and will be considered for inclusion in the predicted segmentation. The next module computes scores for each of these.
3.2 Span Predictor
The span predictor computes a scalar confidence score for each candidate span (i,j) € C, reflecting how likely that subsequence is to form a coherent semantic O syntactic unit. Inspired by boundary- based approaches in segmentation-aware models [11, 15], we model start and end posit tions inde- pendently: This simplification makes inference tractable, allows for efficient parallel scoring, and empirically yields high-quality span proposals across domains 5 We compute unnormalized logits and normalized distributions over token positions: = WsH + bs, &zp" softmax( €8 = WeH + be, &pe softmax(€e)_ where /s , Qe e RL and p; denotes the probability of a span beginning at position i, with p; denoting its end at j. Each span (i, j) is assigned a confidence score by multiplying its boundary probabilities: scoreli,j) = pi Pj
This outer-product scoring approach has been widely used for efficient span extraction in question answering and entity recognition tasks [22, 23]. It biases selection toward spans with high local boundary salience while preserving diversity through length variation: We then extract the top-K scoring candidates: S = TopK {score(i,j) | (i,j) € C} . Proposition 1 (Top-K Marginal Likelihood). Let p8 € 4L and pe € 4L be independent boundary distributions over L token positions. Define the induced span measure P(i,j) = pi p; over the candidate set C = {(i,j) | 1 <i < j < L}. Then, under the independence assumption, the optimal set of K spans that maximizes the total marginal likelihood is given by: S = TopK {P(i,j) | (i,j) € C} ,
and satisfies:
S = arg max P(i,j). S'CC 1S'|=K (i,j)es'
Proof   By construction, each candidate span (i,j) is assigned an  unnormalized confidence score P(i,j) under the product measure derived from independent start and end distributions Since P(i,j) is nonnegative and additive, selecting the top K values of P(i,j) maximizes the total like lihood mass over  any subset of size K: This  corresponds to exact greedy maximization under the monotonic additive objective Z(ij)es Pli,j). The independence assumption ensures that no additional structural constraint or interaction term modifies this score. SThis factorized assumption follows successful precedents in span-based QA [22] and structured pretraining [15].
6