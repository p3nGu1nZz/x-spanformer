\subsection{ONNX Operator Implementation}
\label{sec:onnx-op}

The custom Unigram-LM operator is implemented in C++/CUDA for ONNX Runtime\footnote{Implementation utilizes NVIDIA CUDA 12.0 with cuDNN 8.5 for GPU acceleration and Intel MKL for CPU optimizations.}.  
\begin{itemize}[leftmargin=1.5em]
	\item \textbf{Inputs:} Raw codepoint tensor $[T]$, vocabulary table $\mathcal U_0$.
	\item \textbf{Outputs:} Sparse probability matrix $P\in\mathbb{R}^{T\times V}$.
	\item \textbf{Performance:} Processes 10\,000 tokens in 5ms on A100\footnote{NVIDIA A100 Tensor Core GPU with 40GB HBM2e memory, tested with mixed-precision inference.}, including Viterbi decoding.
\end{itemize}
